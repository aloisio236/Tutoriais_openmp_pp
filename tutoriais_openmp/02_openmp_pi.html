<!<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link href="css/bootstrap.min.css" rel="stylesheet">
        <link rel="stylesheet" href="css/style.css">
        <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Cabin+Sketch">
        <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Reenie+Beanie">
        <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Bitter">
		
		<script src="https://google-code-prettify.googlecode.com/svn/loader/run_prettify.js?lang=css&skin=desert">
		</script>

		<style>
			.prettyprint ol.linenums > li { list-style-type: decimal; }
		</style>
		
        <script>
            (function (i, s, o, g, r, a, m) {
                i['GoogleAnalyticsObject'] = r;
                i[r] = i[r] || function () {
                    (i[r].q = i[r].q || []).push(arguments)
                }, i[r].l = 1 * new Date();
                a = s.createElement(o),
                        m = s.getElementsByTagName(o)[0];
                a.async = 1;
                a.src = g;
                m.parentNode.insertBefore(a, m)
            })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

            ga('create', 'UA-59543538-2', 'auto');
            ga('send', 'pageview');

        </script>

        <script>
            (function (i, s, o, g, r, a, m) {
                i['GoogleAnalyticsObject'] = r;
                i[r] = i[r] || function () {
                    (i[r].q = i[r].q || []).push(arguments)
                }, i[r].l = 1 * new Date();
                a = s.createElement(o),
                        m = s.getElementsByTagName(o)[0];
                a.async = 1;
                a.src = g;
                m.parentNode.insertBefore(a, m)
            })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

            ga('create', 'UA-59543538-1', 'auto');
            ga('send', 'pageview');

        </script>
    </head>
    <body>

        <!-- Título -->
        <div class="jumbotron jumbotron-blue">
          
            <h1>Resolvendo Condições de Disputa em OpenMP</h1>

            <h2>Aloisio Felipe</h2>
            <img src="images/arrows/arrow1.png" class="img-responsive center-block img-logo" />
        </div>

        <!-- Cabeçalho --> 
        <div class="jumbotron jumbotron-white">
            <h1>2º parte</h1> 

            <p>Como medir o tempo de aplicações e calcular o ganho (speedup).</p>		
            <p>Como permitir que várias threads utilizem uma mesma variável compartilhada.</p>
			<p>Como aplicar uma operação de redução em uma variável compartilhada.</p>
        </div>

        <!-- Pré-requisitos -->
        <div class="jumbotron jumbotron-red">
            <h1>pré-requisitos</h1>
            <h3><a href="01_openmp_hello_world.html" class="btn btn-default">Tutorial de Introdução a Programação Paralela com OpenMP</a></h3>
		</div>

        <div class="jumbotron jumbotron-white">
            <h1>calculando o valor de PI</h1>

			<p> O programa sequencial abaixo que calcula o valor de PI usando integração númerica, um método que consome muito tempo de execução.</p>
			
<p><pre class="prettyprint linenums codebox codebox-small">
#include &ltstdio.h&gt

long long num_passos = 1000000000;
double passo;

int main(){
   int i;
   double x, pi, soma=0.0;
   passo = 1.0/(double)num_passos;
	
   for(i=0; i < num_passos; i++){
      x = (i + 0.5)*passo;
      soma = soma + 4.0/(1.0 + x*x);
   }

   pi = soma*passo;
	
   printf("O valor de PI é: %f\n", pi);
   return 0;
}
</pre></p>
			<p> Primeiro copie o código acima para um arquivo chamado pi.c. <br> Vamos então compilar o programa com o seguinte comando: </p><br>

			<p> <span class="label label-default">$ gcc pi.c -o pi</span></p><br>
			
			<p> Para medir o tempo de execução da aplicação, utilize o seguinte comando: </p><br>
						
			<p> <span class="label label-default">$ time ./pi </span></p><br>
			
			<p> Uma saída esperada para esse programa é a seguinte: </p>

<p><pre class="prettyprint linenums codebox codebox-small">
O valor de PI é: 3.141593

real   0m20.805s
user   0m20.783s
sys    0m0.024s
</pre></p>

			<p> Os valores real, user e sys são respectivamente o tempo de execução total que a aplicação gastou (real), o tempo de execução em modo usuário (user) e em modo kernel (sys). Note que o tempo em modo kernel é bem pequeno, pois neste programa não são realizadas muitas chamadas ao sistema operacional. </p> 
			

        </div>

		<div class="jumbotron jumbotron-green">
            <h1>paralelizando o laço de repetição</h1>

			<p> A primeira idéia que temos geralmente é paralelizar a laço de repetição usando a diretiva <b>#pragma omp parallel {...}</b>. Vamos fazer isso e ver o que acontece. </p>
			
<p><pre class="prettyprint linenums codebox codebox-small">
#include &ltstdio.h&gt

long long num_passos = 1000000000;
double passo;

int main(){
   int i;
   double x, pi, soma=0.0;
   passo = 1.0/(double)num_passos;
	
   #pragma omp parallel for	
   for(i=0; i < num_passos; i++){
      x = (i + 0.5)*passo;
      soma = soma + 4.0/(1.0 + x*x);
   }

   pi = soma*passo;
	
   printf("O valor de PI é: %f\n", pi);
   return 0;
}
</pre></p>

			<p> Vamos compilar e executar o programa com os seguintes comandos: </p><br>
			
			<p> <span class="label label-default">$ gcc pi.c -o pi -fopenmp</span></p><br>
			
			<p> <span class="label label-default">$ time ./pi</span></p><br>
			
			<p> Uma saída possível seria a seguinte: </p>

<p><pre class="prettyprint linenums codebox codebox-small">
O valor de PI é: 2.003199

real  0m17.788s
user  0m35.100s
sys   0m0.160s
</pre></p>

			<p>Neste resultado existem três pontos interessantes. O valor de PI está incorreto. O tempo de execução (real) reduziu um pouco e o tempo de usuário dobrou? Pense um pouco sobre isso.</p> <br>

			<p>A redução do tempo de execução é esperada, pois o programa agora roda com duas threads que dividiram as iterações do laço de repetição. O tempo de usuário dobrar também é esperado, pois são somados os tempos de execução das duas threads, mesmo que aproximadamente multiplicar o tempo de execução (real) por dois. Mas o valor de PI estar incorreto, provavelmente indica que paralelização está incompleta. </p> <br>
			
			<p> <span class="label label-primary"> Regra 4 do Paralelismo: Geração de resultados incorretos indica que existem <br><br> conflitos de disputa por variáveis compartilhas não resolvidos. </span></p>
			
		</div>
		
		
        <div class="jumbotron jumbotron-red">
            <h1>identificando os conflitos de disputa</h1>

			<p> Para localizar conflitos de disputa, basta localizar qualquer variável dentro da região paralela que esteja sendo modificada, ou seja, algum valor é atribuído a uma variável ao lado esquerda de um equação. Localiza-as no código abaixo.</p>
			
			
			
<p><pre class="prettyprint linenums codebox codebox-small">
   #pragma omp parallel for	
   for(i=0; i < num_passos; i++){
      x = (i + 0.5)*passo;
      soma = soma + 4.0/(1.0 + x*x);
   }
</pre></p>

			<p> No código acima, podemos identificar 5 variáveis (i,num_passos,x,passo e soma). As variáveis num_passos e passo são apenas de leitura, ou seja nunca são modificadas, logo não geram nenhum conflito. A variável i apesar de ser modificada (i=0, i++), ela é contador do laço de repetição, então ela é privatizada automaticamente pelo parallel for, ou seja, cada thread tem uma cópia local de i. Restam então as variáveis x e soma que são modificadas. </p><br>

			<p> Vamos avaliar a variável x. Faça um teste, se você remover a variável x e colar o que é atribuído a ela diretamente no lugar dos demais x, o seu programa continua correto, como no exemplo abaixo? </p><br>

<p><pre class="prettyprint linenums codebox codebox-medium">
   #pragma omp parallel for	
   for(i=0; i < num_passos; i++){
      soma = soma + 4.0/(1.0 + ((i + 0.5)*passo)*((i + 0.5)*passo));
   }
</pre></p>

			<p> A resposta é sim. Ou seja, x pode ser privada, pois o valor atribuído a x é apenas utilizado dentro da mesma iteração. Isso significa que não existe dependência de dados entre iterações em relação a variável x, portanto x pode ser privado como no exemplo abaixo. </p><br>

<p><pre class="prettyprint linenums codebox codebox-small">
   #pragma omp parallel for private(x)
   for(i=0; i < num_passos; i++){
      x = (i + 0.5)*passo;
      soma = soma + 4.0/(1.0 + x*x);
   }
</pre></p>
			
			<p> Vamos modificar o código conforme o código acima e executar com os comandos abaixo. </p><br>

			<p> <span class="label label-default">$ gcc pi.c -o pi -fopenmp</span></p><br>
			
			<p> <span class="label label-default">$ time ./pi</span></p><br>
			
			<p> Uma saída possível seria a seguinte: </p>
			
<p><pre class="prettyprint linenums codebox codebox-small">
O valor de PI é: 2.108069

real  0m17.977s
user  0m31.341s
sys   0m0.136s
</pre></p>

			<p>Nada mudou muito, pois apesar de termos resolvido o problema de disputa pelo x, ao criar uma cópia privada de x para cada uma das threads, ou seja, não existe mais briga por x, ainda não resolvemos o problema de disputa por soma.
			</p>

			<p> <span class="label label-primary"> Regra 5 do Paralelismo: Variáveis que são apenas utilizadas em uma mesma iteração <br><br> não causam dependências de dados desde que sejam privatizadas. </span></p>

        </div>

       <div class="jumbotron jumbotron-yellow">
            <h1>criando seções críticas</h1>

			<p> A variável soma não pode ser privatizada. Por que? Porque ela é realmente compartilhada pelas demais threads. Pense, ela é o resultado de um somatório. Image que estivéssemos somando de 1 + 2 + 3 + 4. Se a soma fosse privatiazada e cada thread ficasse responsável por somar metade dos elementos, a thread 0 somaria 1 + 2 = 3 e a thread 1 somaria 3 + 4 = 7. Qual seria a resposta certa do somatório? Não seria nem 3 e nem 7, a resposta correta seria a soma dos dois valores, ou seja, 3 + 7 = 10. Então como resolver este problema?</p>
			
			<p> No OpenMP existe um comando chamado <b>#pragma omp critical</b>. Ele cria uma seção crítica ao redor de um comando. Uma seção critíca impede que duas threads executem um mesmo código ao mesmo tempo. Ou seja, se colocarmos uma secção crítica ao redor da linha que modifica a variável soma, a soma continua compatilhada, mas não existe a possibilidade de duas ou mais threads modificarem o seu valor ao mesmo tempo. Isso elimina a condição de disputa.</p>
			
<p><pre class="prettyprint linenums codebox codebox-small">
   #pragma omp parallel for private(x) 
   for(i=0; i < num_passos; i++){
      x = (i + 0.5)*passo;
      #pragma omp critical
      soma = soma + 4.0/(1.0 + x*x);
   }
</pre></p>

			<p> Vamos compilar e executar o programa com os mesmos comandos de antes. </p><br>
			
			<p> Uma saída possível seria a seguinte: </p>

<p><pre class="prettyprint linenums codebox codebox-small">
O valor de PI é: 3.141593

real  0m51.101s
user  1m39.295s
sys   0m0.527s
</pre></p>

			<p>Você vai notar duas coisas interessantes. A primeira é que o valor de PI agora está correto, ou seja, não existem mais condições de disputa. A segunda notícia menos animadora é que o tempo de execução ficou muito maior. Será que paralelismo vale a pena então?</p>

			<p> <span class="label label-primary"> Regra 6 do Paralelismo: Variáveis que são realmente compartilhadas devem ser protegidas <br><br> por seções críticas.  </span></p>


        </div>


       <div class="jumbotron jumbotron-blue">
            <h1>realizando uma redução</h1>

			<p> Por que o programa ficou tão lento? Porque as threads passam a maioria do tempo esperando a outra na seção crítica. Quando uma thread já se encontra seção critica, e uma segunda thread tenta acessá-la, esta segunda thread dorme e só acorda quando a thread anterior sai da seção crítica. Este processo de dormir e acordar consome muito mais tempo do que apenas realização a operação do somatório. Mas existe uma soluão melhor pra este problema.</p>
			
			<p> No OpenMP existe um comando chamado <b>reduction(op:var)</b>, onde var é a variável onde a operação op é aplicado. Uma redução consiste em somar os resultados parciais de cada cada thread até gerar um único valor. Image a situação onde a soma foi privatizada, o único problema foi não somar o 3 + 7, ou seja, somar os resultados parciais de cada thread. É exatamnete isso que a redução faz, ela cria uma variável privada para cada thread, mas no final ela agrupa todos elas em apenas uma variável, como no exemplo abaixo.</p>
			
<p><pre class="prettyprint linenums codebox codebox-small">
   #pragma omp parallel for private(x) reduction(+:soma)
   for(i=0; i < num_passos; i++){
      x = (i + 0.5)*passo;
      soma = soma + 4.0/(1.0 + x*x);
   }
</pre></p>

			<p> Vamos compilar e executar o programa com os mesmos comandos de antes. </p><br>
			
			<p> Uma saída possível seria a seguinte: </p>

<p><pre class="prettyprint linenums codebox codebox-small">
O valor de PI é: 3.141593

real  0m10.620s
user  0m20.732s
sys   0m0.056s
</pre></p>

			<p>Você pode notar que neste resultado, o valor de PI está correto e além disso o tempo caiu pela metade. Ou seja, a aplicação teve um speedup de aproximadamente 2. O speedup é a métrica utilizada para avaliar o ganho de desempenho, dividindo-se o tempo sequencial pelo tempo da versão paralela, no nosso exemplo: 20.8/10.6 = 1.96, ou aproximadamente 2 de speedup, próximo ao speedup linear. Este resultado foi objetivo, por as threads não precisam mais dormir e acordar, ou esperarem para acessar a seção crítica, que deixou de existir com a redução.</p><br>

			<p> <span class="label label-primary"> Regra 7 do Paralelismo: Variáveis compartilhadas que participam de uma operação de redução <br><br> podem ser reduzidas, evitando a necessidade de inserção de seções críticas.  </span></p>
        </div>




        <div class="jumbotron jumbotron-white">
            <h1>próximos passos</h1>

            <p>E se cada iteração do laço de repetição gastar tempos diferentes para serem executados, será que uma thread vai ter mais trabalho que a outra? Veja no nosso próximo tutorial como resolver problemas de desbalanceamento de carga.</p>

            <h3><a href="03_openmp_prime.html" class="btn btn-default">Tutorial Escalonamento de Trabalho em OpenMP</a></h3>
        </div>
		
        <!-- Links Úteis 
        <div class="jumbotron jumbotron-green">
            <h1>links úteis</h1>
-->
<!--            <h3><a href="http://guides.rubyonrails.org/getting_started.html" class="label label-default">Getting Started with Rails</a></h3>	

            <h3><a href="http://www.sitepoint.com/easy-admin-interfaces-active-admin-rails/" class="label label-default">Easy Admin Interfaces with Active Admin</a></h3>	

        </div>
-->
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
        <script src="js/bootstrap.min.js"></script>
    </body>
</html>